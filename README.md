# Prompted Segmentation for Drywall QA

Text-conditioned binary segmentation for drywall defect analysis using:

* **DeepLabV3-ResNet50 + CLIP**
* **Segment Anything Model (ViT-B) + CLIP**

The system generates binary masks (0 / 255) from an input image and a natural language prompt:

* `"segment crack"`
* `"segment taping area"`

## ğŸ“Œ Project Overview

This project trains and evaluates a **single prompt-conditioned segmentation framework** that:

* Accepts an image + text prompt
* Produces a single-channel PNG mask
* Computes IoU and Dice metrics
* Logs inference time and performance

Two architectures were implemented and compared:

1. DeepLab-based prompt fusion model
2. Text-conditioned SAM-based model

# ğŸ“‚ Repository Structure

```
Prompted-Segmentation-for-Drywall-QA/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ crack/
â”‚   â”œâ”€â”€ tapping/
â”‚   â”œâ”€â”€ train_labelled/
â”‚   â”œâ”€â”€ val_labelled/
â”‚   â””â”€â”€ test_labelled/
â”‚
â”œâ”€â”€ predictions/
â”‚
â”œâ”€â”€ train_adam_boundary/
â”œâ”€â”€ training_sam/
â”‚
â”œâ”€â”€ predictions_deeplab.py
â”œâ”€â”€ prediction_SAM.py
â””â”€â”€ other utility scripts

```

## ğŸ“ train_labelled / val_labelled / test_labelled

These are the **combined and processed datasets** used for training and evaluation.

After mask generation:

* Crack and taping datasets were merged
* Original 70% / 15% / 15% splits were preserved
* Images and masks are stored together in unified folders

Structure:

```
train_labelled/
 â”œâ”€â”€ images/
 â””â”€â”€ masks/

val_labelled/
 â”œâ”€â”€ images/
 â””â”€â”€ masks/

test_labelled/
 â”œâ”€â”€ images/
 â””â”€â”€ masks/
```

Each mask:

* Single-channel PNG
* Binary values {0,255}
* Filename format: `imageid__prompt.png`

---

## ğŸ“ predictions/

Contains inference outputs from both models.

Includes:

* Saved prediction masks
* IoU & Dice plots
* CSV metric logs

Separate predictions were generated for:

* DeepLab model
* SAM model

---

## ğŸ“ train_adam_boundary/

Contains:

* DeepLab training scripts
* Training logs (CSV)
* Saved checkpoints
* IoU/Dice plots
* Best model weights

Uses:

* AdamW
* Focal + Dice + Boundary loss

---

## ğŸ“ training_sam/

Contains:

* SAM training scripts
* Logs
* Checkpoints
* Metric plots

Uses:

* SAM ViT-B backbone
* CLIP text projection
* Decoder fine-tuning

---

## ğŸ”§ Key Scripts

### `predictions_deeplab.py`

* Loads trained DeepLab + CLIP model
* Performs inference on test set
* Computes IoU & Dice
* Measures average inference time
* Saves PNG masks

### `prediction_SAM.py`

* Loads trained SAM-based model
* Performs prompt-conditioned inference
* Saves predictions
* Computes metrics
* Generates performance plots

---

# ğŸ“Š Models Implemented

## 1ï¸âƒ£ DeepLab + CLIP

* Backbone: DeepLabV3-ResNet50
* Text Encoder: CLIP ViT-B/32
* Fusion: Feature map + projected text embedding
* Faster inference
* Lightweight compared to SAM

---

## 2ï¸âƒ£ SAM + CLIP

* Backbone: SAM ViT-B
* Text projected into SAM token space
* Mask decoder fine-tuned
* Higher computational cost
* Better structural consistency

---

# ğŸ“ˆ Evaluation

Metrics:

* Mean IoU
* Mean Dice
* Per-image metrics
* Inference time per image

Output:

* PNG masks (0/255)
* CSV logs
* IoU & Dice plots

---

# ğŸš€ How to Run Inference

### DeepLab

```
python predictions_deeplab.py
```

### SAM

```
python prediction_SAM.py
```

### Data source
`Dataset 1 (Taping area):`
https://universe.roboflow.com/objectdetect-pu6rn/drywall-join-detect

`Dataset 2 (Cracks):` 
https://universe.roboflow.com/fyp-ny1jt/cracks-3ii36
